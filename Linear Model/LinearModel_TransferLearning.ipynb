{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/8_sentences_train.csv',sep='|',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train_pos = df_train[df_train['label']==1]\n",
    "df_train_neg = df_train[df_train['label']==0].sample(n = df_train_pos.shape[0])\n",
    "\n",
    "df_array = [df_train_pos,df_train_neg]\n",
    "df_train_balanced = pd.concat(df_array)\n",
    "df_train_balanced = df_train_balanced.sample(frac=1)\n",
    "df_train_balanced = df_train_balanced.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_sentences = df_train_balanced['sentence'] + ' ' + \\\n",
    "                df_train_balanced['prev1'] + ' ' + \\\n",
    "                df_train_balanced['prev2'] + ' ' + \\\n",
    "                df_train_balanced['prev3'] + ' ' + \\\n",
    "                df_train_balanced['prev4']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "vectorizer.fit(all_sentences.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_sentence = vectorizer.transform(df_train_balanced['sentence'].values.astype('U'))\n",
    "X_prev1 = vectorizer.transform(df_train_balanced['prev1'].values.astype('U'))\n",
    "X_prev2 = vectorizer.transform(df_train_balanced['prev2'].values.astype('U'))\n",
    "X_prev3 = vectorizer.transform(df_train_balanced['prev3'].values.astype('U'))\n",
    "X_prev4 = vectorizer.transform(df_train_balanced['prev4'].values.astype('U'))\n",
    "\n",
    "list_sentence = [X_sentence,X_prev1,X_prev2,X_prev3,X_prev4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hstack(list_sentence)\n",
    "y = df_train_balanced['label']\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sp_df = pd.read_csv('data/All-seasons.csv')\n",
    "sp_df = sp_df[sp_df['Season']!='Season']\n",
    "sp_df['Episode_ID'] = sp_df['Season'] + sp_df['Episode']\n",
    "episode_ids = list(set(sp_df['Episode_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed south park dataset shape:  (70625, 6)\n"
     ]
    }
   ],
   "source": [
    "sp_res = pd.DataFrame(columns=['prev4','prev3','prev2','prev1','sentence','Character'])\n",
    "for id in episode_ids:\n",
    "    episode_df = sp_df[sp_df['Episode_ID']==id].reset_index() \n",
    "    res = []\n",
    "    prev4 = \"\"\n",
    "    prev3 = \"\"\n",
    "    prev2 = \"\"\n",
    "    for idx,row in episode_df.iterrows():\n",
    "        if idx==0:\n",
    "            prev1 = row['Line']\n",
    "        else:\n",
    "            sentence = row['Line']\n",
    "            char = row['Character']\n",
    "            res.append([prev4,prev3,prev2,prev1,sentence,char])\n",
    "            prev4 = prev3\n",
    "            prev3 = prev2\n",
    "            prev2 = prev1\n",
    "            prev1 = sentence \n",
    "    local_res = pd.DataFrame(data=res,columns=['prev4','prev3','prev2','prev1','sentence','Character']) \n",
    "    sp_res = sp_res.append(local_res)\n",
    "    \n",
    "    \n",
    "print('processed south park dataset shape: ',sp_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction of sarcasm proportion:  0.194123893805\n"
     ]
    }
   ],
   "source": [
    "X_test_sentence = vectorizer.transform(sp_res['sentence'].values.astype('U'))\n",
    "X_test_prev1 = vectorizer.transform(sp_res['prev1'].values.astype('U'))\n",
    "X_test_prev2 = vectorizer.transform(sp_res['prev2'].values.astype('U'))\n",
    "X_test_prev3 = vectorizer.transform(sp_res['prev3'].values.astype('U'))\n",
    "X_test_prev4 = vectorizer.transform(sp_res['prev4'].values.astype('U'))\n",
    "\n",
    "list_test_sentence = [X_test_sentence,X_test_prev1,X_test_prev2,X_test_prev3,X_test_prev4]\n",
    "\n",
    "X_test = hstack(list_test_sentence)\n",
    "sp_res['sarcasm_prediction']= lr.predict(X_test)\n",
    "\n",
    "print('prediction of sarcasm proportion: ',(sp_res['sarcasm_prediction']==1).sum()/sp_res.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sarcasm_char = sp_res.groupby('Character').agg({'sarcasm_prediction':'sum'})/sp_res.groupby('Character').agg({'sarcasm_prediction':'count'})\n",
    "sarcasm_char['number of sentences'] = sp_res.groupby('Character').agg({'sarcasm_prediction':'count'})\n",
    "\n",
    "sarcasm_char_reduced = sarcasm_char[sarcasm_char['number of sentences']>100]\n",
    "sarcasm_char_reduced2 = sarcasm_char[sarcasm_char['number of sentences']>700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sarcasm_prediction</th>\n",
       "      <th>number of sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Character</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Crowd</th>\n",
       "      <td>0.391304</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kids</th>\n",
       "      <td>0.313869</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Token</th>\n",
       "      <td>0.310469</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clyde</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Boys</th>\n",
       "      <td>0.281818</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man</th>\n",
       "      <td>0.280952</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man 2</th>\n",
       "      <td>0.268293</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ike</th>\n",
       "      <td>0.265000</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenny</th>\n",
       "      <td>0.257955</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Man 1</th>\n",
       "      <td>0.257426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Craig</th>\n",
       "      <td>0.254601</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chris</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mephesto</th>\n",
       "      <td>0.241135</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timmy</th>\n",
       "      <td>0.239544</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerald</th>\n",
       "      <td>0.237560</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Towelie</th>\n",
       "      <td>0.234848</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark</th>\n",
       "      <td>0.232143</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satan</th>\n",
       "      <td>0.227723</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Butters</th>\n",
       "      <td>0.226466</td>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bebe</th>\n",
       "      <td>0.222727</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pete</th>\n",
       "      <td>0.216216</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yates</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wendy</th>\n",
       "      <td>0.205832</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyle</th>\n",
       "      <td>0.203926</td>\n",
       "      <td>7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jimmy</th>\n",
       "      <td>0.203704</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stan</th>\n",
       "      <td>0.201516</td>\n",
       "      <td>7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Officer Barbrady</th>\n",
       "      <td>0.201149</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott</th>\n",
       "      <td>0.197917</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ned</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Narrator</th>\n",
       "      <td>0.194631</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Terrance</th>\n",
       "      <td>0.191489</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs. Garrison</th>\n",
       "      <td>0.189091</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cartman</th>\n",
       "      <td>0.188303</td>\n",
       "      <td>9729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbrady</th>\n",
       "      <td>0.186667</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweek</th>\n",
       "      <td>0.184549</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Randy</th>\n",
       "      <td>0.182927</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Garrison</th>\n",
       "      <td>0.181174</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jesus</th>\n",
       "      <td>0.179487</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Mackey</th>\n",
       "      <td>0.179200</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stuart</th>\n",
       "      <td>0.176871</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sarcasm_prediction  number of sentences\n",
       "Character                                                \n",
       "Crowd                       0.391304                  115\n",
       "Kids                        0.313869                  137\n",
       "Token                       0.310469                  277\n",
       "Clyde                       0.285714                  315\n",
       "The Boys                    0.281818                  110\n",
       "Man                         0.280952                  210\n",
       "Man 2                       0.268293                  123\n",
       "Ike                         0.265000                  200\n",
       "Kenny                       0.257955                  880\n",
       "Man 1                       0.257426                  101\n",
       "Craig                       0.254601                  326\n",
       "Chris                       0.250000                  192\n",
       "Mephesto                    0.241135                  141\n",
       "Timmy                       0.239544                  263\n",
       "Gerald                      0.237560                  623\n",
       "Towelie                     0.234848                  132\n",
       "Mark                        0.232143                  112\n",
       "Satan                       0.227723                  202\n",
       "Butters                     0.226466                 2592\n",
       "Bebe                        0.222727                  220\n",
       "Pete                        0.216216                  111\n",
       "Yates                       0.208333                  120\n",
       "Wendy                       0.205832                  583\n",
       "Kyle                        0.203926                 7081\n",
       "Jimmy                       0.203704                  594\n",
       "Stan                        0.201516                 7652\n",
       "Officer Barbrady            0.201149                  174\n",
       "Scott                       0.197917                  192\n",
       "Ned                         0.196078                  102\n",
       "Narrator                    0.194631                  149\n",
       "Terrance                    0.191489                  282\n",
       "Mrs. Garrison               0.189091                  275\n",
       "Cartman                     0.188303                 9729\n",
       "Barbrady                    0.186667                  150\n",
       "Tweek                       0.184549                  233\n",
       "Randy                       0.182927                 2460\n",
       "Mr. Garrison                0.181174                  988\n",
       "Jesus                       0.179487                  312\n",
       "Mr. Mackey                  0.179200                  625\n",
       "Stuart                      0.176871                  147"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_char_reduced.sort_values('sarcasm_prediction',ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sarcasm_prediction</th>\n",
       "      <th>number of sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Character</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kenny</th>\n",
       "      <td>0.257955</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Butters</th>\n",
       "      <td>0.226466</td>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyle</th>\n",
       "      <td>0.203926</td>\n",
       "      <td>7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stan</th>\n",
       "      <td>0.201516</td>\n",
       "      <td>7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cartman</th>\n",
       "      <td>0.188303</td>\n",
       "      <td>9729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Randy</th>\n",
       "      <td>0.182927</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr. Garrison</th>\n",
       "      <td>0.181174</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chef</th>\n",
       "      <td>0.173581</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharon</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sarcasm_prediction  number of sentences\n",
       "Character                                            \n",
       "Kenny                   0.257955                  880\n",
       "Butters                 0.226466                 2592\n",
       "Kyle                    0.203926                 7081\n",
       "Stan                    0.201516                 7652\n",
       "Cartman                 0.188303                 9729\n",
       "Randy                   0.182927                 2460\n",
       "Mr. Garrison            0.181174                  988\n",
       "Chef                    0.173581                  916\n",
       "Sharon                  0.166667                  858"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_char_reduced2.sort_values('sarcasm_prediction',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
